// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: google/cloud/dialogflow/v2beta1/audio_config.proto

package com.google.cloud.dialogflow.v2beta1;

public interface InputAudioConfigOrBuilder extends
    // @@protoc_insertion_point(interface_extends:google.cloud.dialogflow.v2beta1.InputAudioConfig)
    com.google.protobuf.MessageOrBuilder {

  /**
   * <pre>
   * Required. Audio encoding of the audio content to process.
   * </pre>
   *
   * <code>.google.cloud.dialogflow.v2beta1.AudioEncoding audio_encoding = 1;</code>
   * @return The enum numeric value on the wire for audioEncoding.
   */
  int getAudioEncodingValue();
  /**
   * <pre>
   * Required. Audio encoding of the audio content to process.
   * </pre>
   *
   * <code>.google.cloud.dialogflow.v2beta1.AudioEncoding audio_encoding = 1;</code>
   * @return The audioEncoding.
   */
  com.google.cloud.dialogflow.v2beta1.AudioEncoding getAudioEncoding();

  /**
   * <pre>
   * Required. Sample rate (in Hertz) of the audio content sent in the query.
   * Refer to
   * [Cloud Speech API
   * documentation](https://cloud.google.com/speech-to-text/docs/basics) for
   * more details.
   * </pre>
   *
   * <code>int32 sample_rate_hertz = 2;</code>
   * @return The sampleRateHertz.
   */
  int getSampleRateHertz();

  /**
   * <pre>
   * Required. The language of the supplied audio. Dialogflow does not do
   * translations. See [Language
   * Support](https://cloud.google.com/dialogflow/docs/reference/language)
   * for a list of the currently supported language codes. Note that queries in
   * the same session do not necessarily need to specify the same language.
   * </pre>
   *
   * <code>string language_code = 3;</code>
   * @return The languageCode.
   */
  java.lang.String getLanguageCode();
  /**
   * <pre>
   * Required. The language of the supplied audio. Dialogflow does not do
   * translations. See [Language
   * Support](https://cloud.google.com/dialogflow/docs/reference/language)
   * for a list of the currently supported language codes. Note that queries in
   * the same session do not necessarily need to specify the same language.
   * </pre>
   *
   * <code>string language_code = 3;</code>
   * @return The bytes for languageCode.
   */
  com.google.protobuf.ByteString
      getLanguageCodeBytes();

  /**
   * <pre>
   * If `true`, Dialogflow returns [SpeechWordInfo][google.cloud.dialogflow.v2beta1.SpeechWordInfo] in
   * [StreamingRecognitionResult][google.cloud.dialogflow.v2beta1.StreamingRecognitionResult] with information about the recognized speech
   * words, e.g. start and end time offsets. If false or unspecified, Speech
   * doesn't return any word-level information.
   * </pre>
   *
   * <code>bool enable_word_info = 13;</code>
   * @return The enableWordInfo.
   */
  boolean getEnableWordInfo();

  /**
   * <pre>
   * A list of strings containing words and phrases that the speech
   * recognizer should recognize with higher likelihood.
   * See [the Cloud Speech
   * documentation](https://cloud.google.com/speech-to-text/docs/basics#phrase-hints)
   * for more details.
   * This field is deprecated. Please use [speech_contexts]() instead. If you
   * specify both [phrase_hints]() and [speech_contexts](), Dialogflow will
   * treat the [phrase_hints]() as a single additional [SpeechContext]().
   * </pre>
   *
   * <code>repeated string phrase_hints = 4 [deprecated = true];</code>
   * @return A list containing the phraseHints.
   */
  @java.lang.Deprecated java.util.List<java.lang.String>
      getPhraseHintsList();
  /**
   * <pre>
   * A list of strings containing words and phrases that the speech
   * recognizer should recognize with higher likelihood.
   * See [the Cloud Speech
   * documentation](https://cloud.google.com/speech-to-text/docs/basics#phrase-hints)
   * for more details.
   * This field is deprecated. Please use [speech_contexts]() instead. If you
   * specify both [phrase_hints]() and [speech_contexts](), Dialogflow will
   * treat the [phrase_hints]() as a single additional [SpeechContext]().
   * </pre>
   *
   * <code>repeated string phrase_hints = 4 [deprecated = true];</code>
   * @return The count of phraseHints.
   */
  @java.lang.Deprecated int getPhraseHintsCount();
  /**
   * <pre>
   * A list of strings containing words and phrases that the speech
   * recognizer should recognize with higher likelihood.
   * See [the Cloud Speech
   * documentation](https://cloud.google.com/speech-to-text/docs/basics#phrase-hints)
   * for more details.
   * This field is deprecated. Please use [speech_contexts]() instead. If you
   * specify both [phrase_hints]() and [speech_contexts](), Dialogflow will
   * treat the [phrase_hints]() as a single additional [SpeechContext]().
   * </pre>
   *
   * <code>repeated string phrase_hints = 4 [deprecated = true];</code>
   * @param index The index of the element to return.
   * @return The phraseHints at the given index.
   */
  @java.lang.Deprecated java.lang.String getPhraseHints(int index);
  /**
   * <pre>
   * A list of strings containing words and phrases that the speech
   * recognizer should recognize with higher likelihood.
   * See [the Cloud Speech
   * documentation](https://cloud.google.com/speech-to-text/docs/basics#phrase-hints)
   * for more details.
   * This field is deprecated. Please use [speech_contexts]() instead. If you
   * specify both [phrase_hints]() and [speech_contexts](), Dialogflow will
   * treat the [phrase_hints]() as a single additional [SpeechContext]().
   * </pre>
   *
   * <code>repeated string phrase_hints = 4 [deprecated = true];</code>
   * @param index The index of the value to return.
   * @return The bytes of the phraseHints at the given index.
   */
  @java.lang.Deprecated com.google.protobuf.ByteString
      getPhraseHintsBytes(int index);

  /**
   * <pre>
   * Context information to assist speech recognition.
   * See [the Cloud Speech
   * documentation](https://cloud.google.com/speech-to-text/docs/basics#phrase-hints)
   * for more details.
   * </pre>
   *
   * <code>repeated .google.cloud.dialogflow.v2beta1.SpeechContext speech_contexts = 11;</code>
   */
  java.util.List<com.google.cloud.dialogflow.v2beta1.SpeechContext> 
      getSpeechContextsList();
  /**
   * <pre>
   * Context information to assist speech recognition.
   * See [the Cloud Speech
   * documentation](https://cloud.google.com/speech-to-text/docs/basics#phrase-hints)
   * for more details.
   * </pre>
   *
   * <code>repeated .google.cloud.dialogflow.v2beta1.SpeechContext speech_contexts = 11;</code>
   */
  com.google.cloud.dialogflow.v2beta1.SpeechContext getSpeechContexts(int index);
  /**
   * <pre>
   * Context information to assist speech recognition.
   * See [the Cloud Speech
   * documentation](https://cloud.google.com/speech-to-text/docs/basics#phrase-hints)
   * for more details.
   * </pre>
   *
   * <code>repeated .google.cloud.dialogflow.v2beta1.SpeechContext speech_contexts = 11;</code>
   */
  int getSpeechContextsCount();
  /**
   * <pre>
   * Context information to assist speech recognition.
   * See [the Cloud Speech
   * documentation](https://cloud.google.com/speech-to-text/docs/basics#phrase-hints)
   * for more details.
   * </pre>
   *
   * <code>repeated .google.cloud.dialogflow.v2beta1.SpeechContext speech_contexts = 11;</code>
   */
  java.util.List<? extends com.google.cloud.dialogflow.v2beta1.SpeechContextOrBuilder> 
      getSpeechContextsOrBuilderList();
  /**
   * <pre>
   * Context information to assist speech recognition.
   * See [the Cloud Speech
   * documentation](https://cloud.google.com/speech-to-text/docs/basics#phrase-hints)
   * for more details.
   * </pre>
   *
   * <code>repeated .google.cloud.dialogflow.v2beta1.SpeechContext speech_contexts = 11;</code>
   */
  com.google.cloud.dialogflow.v2beta1.SpeechContextOrBuilder getSpeechContextsOrBuilder(
      int index);

  /**
   * <pre>
   * Which Speech model to select for the given request. Select the
   * model best suited to your domain to get best results. If a model is not
   * explicitly specified, then we auto-select a model based on the parameters
   * in the InputAudioConfig.
   * If enhanced speech model is enabled for the agent and an enhanced
   * version of the specified model for the language does not exist, then the
   * speech is recognized using the standard version of the specified model.
   * Refer to
   * [Cloud Speech API
   * documentation](https://cloud.google.com/speech-to-text/docs/basics#select-model)
   * for more details.
   * </pre>
   *
   * <code>string model = 7;</code>
   * @return The model.
   */
  java.lang.String getModel();
  /**
   * <pre>
   * Which Speech model to select for the given request. Select the
   * model best suited to your domain to get best results. If a model is not
   * explicitly specified, then we auto-select a model based on the parameters
   * in the InputAudioConfig.
   * If enhanced speech model is enabled for the agent and an enhanced
   * version of the specified model for the language does not exist, then the
   * speech is recognized using the standard version of the specified model.
   * Refer to
   * [Cloud Speech API
   * documentation](https://cloud.google.com/speech-to-text/docs/basics#select-model)
   * for more details.
   * </pre>
   *
   * <code>string model = 7;</code>
   * @return The bytes for model.
   */
  com.google.protobuf.ByteString
      getModelBytes();

  /**
   * <pre>
   * Which variant of the [Speech model][google.cloud.dialogflow.v2beta1.InputAudioConfig.model] to use.
   * </pre>
   *
   * <code>.google.cloud.dialogflow.v2beta1.SpeechModelVariant model_variant = 10;</code>
   * @return The enum numeric value on the wire for modelVariant.
   */
  int getModelVariantValue();
  /**
   * <pre>
   * Which variant of the [Speech model][google.cloud.dialogflow.v2beta1.InputAudioConfig.model] to use.
   * </pre>
   *
   * <code>.google.cloud.dialogflow.v2beta1.SpeechModelVariant model_variant = 10;</code>
   * @return The modelVariant.
   */
  com.google.cloud.dialogflow.v2beta1.SpeechModelVariant getModelVariant();

  /**
   * <pre>
   * If `false` (default), recognition does not cease until the
   * client closes the stream.
   * If `true`, the recognizer will detect a single spoken utterance in input
   * audio. Recognition ceases when it detects the audio's voice has
   * stopped or paused. In this case, once a detected intent is received, the
   * client should close the stream and start a new request with a new stream as
   * needed.
   * Note: This setting is relevant only for streaming methods.
   * Note: When specified, InputAudioConfig.single_utterance takes precedence
   * over StreamingDetectIntentRequest.single_utterance.
   * </pre>
   *
   * <code>bool single_utterance = 8;</code>
   * @return The singleUtterance.
   */
  boolean getSingleUtterance();

  /**
   * <pre>
   * Only used in [Participants.AnalyzeContent][google.cloud.dialogflow.v2beta1.Participants.AnalyzeContent] and
   * [Participants.StreamingAnalyzeContent][google.cloud.dialogflow.v2beta1.Participants.StreamingAnalyzeContent].
   * If `false` and recognition doesn't return any result, trigger
   * `NO_SPEECH_RECOGNIZED` event to Dialogflow agent.
   * </pre>
   *
   * <code>bool disable_no_speech_recognized_event = 14;</code>
   * @return The disableNoSpeechRecognizedEvent.
   */
  boolean getDisableNoSpeechRecognizedEvent();
}
